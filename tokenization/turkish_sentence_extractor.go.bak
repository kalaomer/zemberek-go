package tokenization

import (
	"regexp"
	"strings"
	"unicode"

	"github.com/kalaomer/zemberek-go/core/turkish"
)

var (
	boundaryChars  = map[rune]bool{'.': true, '!': true, '?': true, '…': true}
	doubleQuotes   = map[rune]bool{'"': true, '"': true, '"': true, '»': true, '«': true}
	punctuationReg = regexp.MustCompile(`[.!?…]`)
)

// TurkishSentenceExtractor separates sentences using perceptron model and rule-based approaches
type TurkishSentenceExtractor struct {
	*PerceptronSegmenter
	Weights                      map[string]float64
	DoNotSplitInDoubleQuotes     bool
	AbbrSet                      map[string]bool
}

// NewTurkishSentenceExtractor creates a new sentence extractor
func NewTurkishSentenceExtractor(doNotSplitInDoubleQuotes bool, weightsPath string) (*TurkishSentenceExtractor, error) {
	weights, err := LoadWeightsFromCSV(weightsPath)
	if err != nil {
		return nil, err
	}

	return &TurkishSentenceExtractor{
		PerceptronSegmenter:      NewPerceptronSegmenter(),
		Weights:                  weights,
		DoNotSplitInDoubleQuotes: doNotSplitInDoubleQuotes,
		AbbrSet:                  LoadAbbreviations(""),
	}, nil
}

// ExtractToSpans divides paragraph into spans
func (t *TurkishSentenceExtractor) ExtractToSpans(paragraph string) []*Span {
	spans := make([]*Span, 0)
	begin := 0

	runes := []rune(paragraph)

	for j, ch := range runes {
		if boundaryChars[ch] {
			boundaryData := NewBoundaryData(paragraph, j, t.AbbrSet)
			if !boundaryData.NonBoundaryCheck() {
				features := boundaryData.ExtractFeatures()
				score := 0.0

				for _, feature := range features {
					score += t.GetWeight(feature)
				}

				if score > 0.0 {
					span, _ := NewSpan(begin, j+1)
					if span.GetLength() > 0 {
						spans = append(spans, span)
					}
					begin = j + 1
				}
			}
		}
	}

	if begin < len(runes) {
		span, _ := NewSpan(begin, len(runes))
		if span.GetLength() > 0 {
			spans = append(spans, span)
		}
	}

	return spans
}

// FromParagraph extracts sentences from a paragraph
func (t *TurkishSentenceExtractor) FromParagraph(paragraph string) []string {
	spans := t.ExtractToSpans(paragraph)
	sentences := make([]string, 0)

	for _, span := range spans {
		sentence := strings.TrimSpace(span.GetSubString(paragraph))
		if len(sentence) > 0 {
			sentences = append(sentences, sentence)
		}
	}

	return sentences
}

// GetWeight returns the weight for a feature
func (t *TurkishSentenceExtractor) GetWeight(key string) float64 {
	if weight, ok := t.Weights[key]; ok {
		return weight
	}
	return 0.0
}

// BoundaryData represents various features for a character at a specific index
type BoundaryData struct {
	PreviousLetter              rune
	NextLetter                  rune
	PreviousTwoLetters          string
	NextTwoLetters              string
	PreviousSpace               int
	LeftChunk                   string
	PreviousBoundaryOrSpace     int
	LeftChunkUntilBoundary      string
	NextSpace                   int
	RightChunk                  string
	NextBoundaryOrSpace         int
	RightChunkUntilBoundary     string
	CurrentChar                 rune
	CurrentWord                 string
	CurrentWordNoPunctuation    string
	NextWord                    string
	AbbrSet                     map[string]bool
}

// NewBoundaryData creates boundary data for a position in the string
func NewBoundaryData(inputString string, pointer int, abbrSet map[string]bool) *BoundaryData {
	runes := []rune(inputString)
	bd := &BoundaryData{AbbrSet: abbrSet}

	if pointer > 0 {
		bd.PreviousLetter = runes[pointer-1]
	} else {
		bd.PreviousLetter = '_'
	}

	if pointer < len(runes)-1 {
		bd.NextLetter = runes[pointer+1]
	} else {
		bd.NextLetter = '_'
	}

	if pointer > 1 {
		bd.PreviousTwoLetters = string(runes[pointer-2 : pointer])
	} else {
		bd.PreviousTwoLetters = "__"
	}

	if pointer < len(runes)-2 {
		bd.NextTwoLetters = string(runes[pointer+1 : pointer+3])
	} else {
		bd.NextTwoLetters = "__"
	}

	bd.PreviousSpace = findBackwardsSpaceOrChar(runes, pointer, ' ')
	bd.LeftChunk = string(runes[bd.PreviousSpace:pointer])
	bd.PreviousBoundaryOrSpace = findBackwardsSpaceOrChar(runes, pointer, '.')
	if bd.PreviousSpace == bd.PreviousBoundaryOrSpace {
		bd.LeftChunkUntilBoundary = bd.LeftChunk
	} else {
		bd.LeftChunkUntilBoundary = string(runes[bd.PreviousBoundaryOrSpace:pointer])
	}

	bd.NextSpace = findForwardsSpaceOrChar(runes, pointer, ' ')
	if pointer < len(runes)-1 {
		bd.RightChunk = string(runes[pointer+1 : bd.NextSpace])
	} else {
		bd.RightChunk = ""
	}

	bd.NextBoundaryOrSpace = findForwardsSpaceOrChar(runes, pointer, '.')
	if bd.NextSpace == bd.NextBoundaryOrSpace {
		bd.RightChunkUntilBoundary = bd.RightChunk
	} else {
		bd.RightChunkUntilBoundary = string(runes[pointer+1 : bd.NextBoundaryOrSpace])
	}

	bd.CurrentChar = runes[pointer]
	bd.CurrentWord = bd.LeftChunk + string(bd.CurrentChar) + bd.RightChunk
	bd.CurrentWordNoPunctuation = punctuationReg.ReplaceAllString(bd.CurrentWord, "")

	// Find next word
	if bd.NextSpace+1 < len(runes) {
		nextWordEnd := bd.NextSpace + 1
		for nextWordEnd < len(runes) && runes[nextWordEnd] != ' ' {
			nextWordEnd++
		}
		bd.NextWord = string(runes[bd.NextSpace+1 : nextWordEnd])
	} else {
		bd.NextWord = ""
	}

	return bd
}

func findBackwardsSpaceOrChar(runes []rune, pos int, char rune) int {
	for i := pos - 1; i >= 0; i-- {
		if runes[i] == ' ' || runes[i] == char {
			return i + 1
		}
	}
	return 0
}

func findForwardsSpaceOrChar(runes []rune, pos int, char rune) int {
	for i := pos + 1; i < len(runes); i++ {
		if runes[i] == ' ' || runes[i] == char {
			return i
		}
	}
	return len(runes)
}

// NonBoundaryCheck checks if current position is a potential sentence boundary
func (bd *BoundaryData) NonBoundaryCheck() bool {
	return len([]rune(bd.LeftChunkUntilBoundary)) == 1 ||
		bd.NextLetter == '\'' ||
		boundaryChars[bd.NextLetter] ||
		bd.AbbrSet[bd.CurrentWord] ||
		bd.AbbrSet[bd.LeftChunkUntilBoundary] ||
		PotentialWebsite(bd.CurrentWord)
}

// ExtractFeatures extracts features for the current position
func (bd *BoundaryData) ExtractFeatures() []string {
	features := make([]string, 0)

	features = append(features, "1:"+boolToString(unicode.IsUpper(bd.PreviousLetter)))
	features = append(features, "1b:"+boolToString(unicode.IsSpace(bd.NextLetter)))
	features = append(features, "1a:"+string(bd.PreviousLetter))
	features = append(features, "1b:"+string(bd.NextLetter))
	features = append(features, "2p:"+bd.PreviousTwoLetters)
	features = append(features, "2n:"+bd.NextTwoLetters)

	if len(bd.CurrentWord) > 0 {
		features = append(features, "7c:"+boolToString(unicode.IsUpper([]rune(bd.CurrentWord)[0])))
		features = append(features, "9c:"+GetMetaChar(bd.CurrentWord))
	}

	if len(bd.RightChunk) > 0 {
		features = append(features, "7r:"+boolToString(unicode.IsUpper([]rune(bd.RightChunk)[0])))
		features = append(features, "9r:"+GetMetaChar(bd.RightChunk))
	}

	if len(bd.LeftChunk) > 0 && !turkish.Instance.ContainsVowel(bd.LeftChunk) {
		features = append(features, "lcc:true")
	}

	if len(bd.CurrentWordNoPunctuation) > 0 {
		allUp := true
		allDigit := true

		for _, c := range bd.CurrentWordNoPunctuation {
			if !unicode.IsUpper(c) {
				allUp = false
			}
			if !unicode.IsDigit(c) {
				allDigit = false
			}
		}

		if allUp {
			features = append(features, "11u:true")
		}
		if allDigit {
			features = append(features, "11d:true")
		}
	}

	return features
}

func boolToString(b bool) string {
	if b {
		return "true"
	}
	return "false"
}
